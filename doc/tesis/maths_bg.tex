\section{Background matem\'atico}
\label{sec:math_bg}
\subsection{Sobre estad\'istica bayesiana}
Una de las decisiones sobre el alcance de este trabajo es que los modelos construidos ser'an entrenados s'olo con un tema por vez. 
Esta decisi'on evita el problema de tener que combinar la informaci'on proporcionada por varias piezas musicales. Sin embargo, el precio que debe pagarse 
es que para muchos modelos de los que se expondr'an no alcanza solamente con entrenar con una pieza musical, puesto que ciertas estimaciones no ser'ian estad'isticamente 
significativas. 

Una soluci'on a este problema es adoptar una postura bayesiana y tener una creencia previa sobre las caracter'isticas del fen'omeno a modelar, 
y luego actualizar esta creencia previa con la evidencia observada. De esta forma, si el modelo esta basado en una teor'ia cognitiva, se puede utilizar
como creencia previa alg'un estudio donde se haya puesto a prueba esta teor'ia. 

Otra raz'on para utilizar creencias previas es para estimar distribuci'ones de probabilidades suaves, en el sentido de que no asignen valor $0$ a un evento 
por el s'olo hecho de no haberlo observado en la etapa de entrenamiento. 

Escribiendo esto matem'aticamente, sup'ongase que se cuenta con un mo\-delo parametrizado por un vector $\theta$. 
La creencia previa sobre el fen'omeno a modelar, b'asicamente estar'ia restringiendo \emph{a priori} qu'e par'ametros son m'as probables que otros. 
Esta informaci'on se codifica como una distribuci'on de probabilidades sobre $\theta$, $P(\theta)$. 

Sup'ongase ahora que se cuenta con cierta evidencia de entrenamiento $x_1,\cdots,x_n$. Al entrenar el modelo, uno quisiera combinar la 
creencia previa dada por $P(\theta)$ junto con la evidencia dada por $x_1,\cdots,x_n$ en una distribuci'on \emph{a posteriori} sobre los par'ametros.
Utilizando la ley de Bayes y la ley de probabilidad total, es posible reescribir la distribuci'on a posteriori de $\theta$ en funci'on de su creencia previa y 
la probabilidad de la observaci'on:

\begin{align*}
P(\theta|x_1,\cdots,x_n) &= \frac{P(x_1,\cdots,x_n|\theta) P(\theta)}{P(x_1,\cdots,x_n)} \\
                         &= \frac{P(x_1,\cdots,x_n|\theta) P(\theta)}{\int_\theta{P(x_1,\cdots,x_n|\theta)P(\theta)\mathrm{d}\theta}}
\end{align*}

Utilizando ahora la creencia a posteriori sobre $\theta$, la probabilidad de una nueva observaci'on $x$ est'a dada por

$$P(x|x_1,\cdots,x_n) = \int_\theta{P(x|\theta)P(\theta|x_1,\cdots,x_n)}$$

N'otese que el resultado de hacer esto elimina el par'ametro $\theta$ como valor, y se utilizan todos los valores posibles asociados a la creencia de que efectivamente
sea ese el valor que parametriza a la distribuci'on que genera las obervaciones.


Un principal problema al aplicar estas t'ecnicas es la resoluci'on de las integrales sobre el espacio de par'ametros, que suele ser multidimensional. 
Sin embargo, hay casos en donde se conocen expresiones anal'iticas para la probabilidad a posteriori de los par'ametros, y en ese caso, se puede utilizar
como p'arametro $E(\theta|x_1,\cdots,x_n)$ \alert{argumentar bien, montacarlo de la intergral converje a la esperanza}%\footnote{El lector interesado en la justificaci'on referirse a ??? %}.

La mayor'ia de los modelos propuestos en este trabajo deben elejir un elemento dentro de un conjunto finito de elementos. Esto
se puede modelar como tomar un sample de una variable multinomial. En este caso, si se codifica la creencia previa
sobre $\theta$ como una distribucion Dirichlet, se puede calcular de una forma muy facil la distribuci'on a posteriori de $\theta$ dado por la siguiente
f'ormula:

$$ \theta \sim Dirichlet(\alpha_1,\cdots,\alpha_k) \Rightarrow \theta|x_1,\cdots,x_n \sim Dirichet(\alpha_1+n_1,\cdots,\alpha_k+n_k)$$

Donde los valores $x_i$ pueden tomar uno de $k$ valores posibles, y $n_j=\sum_{i=1}^n\delta_{x_i, v_j}$, siendo $v_j$ el j-'esimo posible valor 
que puede tomar $x_i$, y $\delta_{a,b} = 1 \Leftrightarrow a = b$, si no, $\delta_{a, b} = 0$. 

Utilizando esta f'ormula es posible calcular anal'iticamente la distribuci'on a posteriori de la observaci'on, y luego tomar la esperanza dada por

$$E(\theta|x_1,\cdots,x_n)=\frac{\alpha_i + n_i}{\sum_{j=1}^{k}{\alpha_j+n_j}}$$

N'otese que cuanto m'as grande es $\alpha_j$, mayor cantidad de observaciones ser'an necesarias para contradecir la creencia previa. 
Una forma natural de tomar en cuenta este comportamiento es descomponer los valores de $\alpha_i$ en un producto entre la distribuci'on a priori que explica el fen'omeno 
y un factor de peso, es decir 
$\alpha_i=p_i\times\alpha$, donde $p_i$ es la probabilidad a priori de observar el valor $v_i$, y $\alpha$ el factor de peso sobre esa creencia. En
el caso que no se cuente con informaci'on previa sobre el fen'omeno y solamente se quiera suavizar la estimaci'on, se puede considerar una creencia
previa uniforme.

%
%\subsection{Combinaci\'ones de distribuci\'ones de probabilidad}
%Una operaci'on muy frecuentemente utilizada a lo largo del presente trabajo es la \texttt{combinaci'on convexa} entre distribuciones
%de probabilidad.
%
%Dadas $p$ y $q$, dos distribuci'ones de probabilidad sobre el conjunto $S$, y un n'umero $0 \leq \alpha \leq 1$, 
%se nota $p +_\alpha q$ a la combinaci'on convexa entre $p$ y $q$, y se define:
%$$(p +_\alpha q)(A) = \alpha \times p(A) + (1-\alpha) \times q(A)$$ 
%
%En caso de referirse a $p+q$, se asume que $\alpha = 1/2$. 
%\newline \newline
%Observaci'ones:
%\begin{itemize}
% \item Se puede demostrar que el resultado de combinar dos distribuci'ones de probabilidad de esta forma es tambi'en una distribuci'on 
%de probabilidad.
%
% \item Notar que esta definici'on puede extenderse para $n$ distribuci'ones de probabilidad. En ese caso se necesitar'an valores 
%$\alpha_1, \dots, \alpha_n$, tales que $\sum_i \alpha_i = 1$. En general, se utilizara $\alpha_i = 1/n$ salvo que se aclare lo contrario.
%\end{itemize}
%

\subsection{Cadenas de Markov}
Sup'ongase que se desea modelar la evoluci'on de un sistema con respecto al tiempo. Es de esperarse que 
el estado en el que se encuentra el sistema en cierto momento de alguna forma tenga que ver con la historia por la que este transit'o
previamente. 

Las cadenas de Markov de orden $k$ permiten modelar este tipo de dependencias haciendo una asunci'on: la probabilidad de que el sistema vaya a un cierto estado
dado la historia de estados por los que transit'o \emph{s'olo} depende de los 'ultimos $k$ estados anteriores en los que este transit'o. 
Esta asunci'on es conocida como la propiedad de Markov. 

Formalmente, una cadena de Markov de orden $k$ es una tripla $<S,\pi, P>$, donde $S$ es el conjunto de posibles estados del sistema, $\pi$ la distribuci'on
inicial para los estados y $P$ la 
distribuci'on de transici'on, es decir, dados $s_1, \cdots, s_{t+1} \in S$, el valor de $P(s_{t+1} | s_1, \cdots, s_t)$ indica la probabilidad
de que el sistema pase estado $s_{t+1}$ dado que a transitado por los estados $s_1, \cdots, s_t$. 
Volviendo a la propiedad de Markov, ahora es posible expresarla formalmente: $$P(s_{t+1}|s_1,\cdots,s_t) = P(s_{t+1} | s_{t-k}, \cdots, s_t)$$

A modo ilustrativo, sup'ongase que se desea modelar el clima con una cadena de Markov de orden 1, restringiendo el clima a si llueve o no. Siendo as'i, el conjunto 
$S$ de estados ser'a $\{llueve, no\ llueve\}$. 

Asumiendo que las probabilidades de transici'on son las dadas en la siguiente tabla, el sistema gr'aficamente se ver'ia como la figura \ref{fig:markov_clima}

\begin{center}
\label{tabla_markov}
\begin{tabular}{l l l l}
$P(lluvia | lluvia) $ & $=0.9$ & $P(lluvia | no\ llueve) $& $=0.1$\\
$P(no\ lluvia | lluvia)  $ & $=0.3$ & $P(no\ lluvia | no\ llueve) $ & $=0.7$\\
\end{tabular}
\end{center}

\begin{imagen}
    \file{images/weather_graph.png}
    \labelname{fig:markov_clima}
    \desc{Representaci'on gr'afica de la cadena de Markov}
    \width{5cm}
\end{imagen}

Una caminata al azar es una sucesi'on $s_1, \cdots, s_t$ de estados, donde $s_1$ es elegido de acuerdo a $\pi$, 
y el resto de los estados de la sucesi'on cada uno elegidos seg'un la matriz de transici'on. De esta forma, en el ejemplo de la figura \ref{fig:markov_clima} y asumiendo 
que $\pi$ asigna probabilidad uniforme a los dos estados, la caminata al azar formada por los estados $lluvia, no\ lluvia, no\ lluvia$ tendr'a probabilidad $0.5\times0.3\times0.7$. 

Se entiende que esta introducci'on es incompleta, sin embargo en esta tesis s'olo se utilizar'an las cadenas de Markov para luego realizar 
caminatas al azar sobre ellas. El lector interesado en profundizar en cadenas de markov puede ver \cite{Rabiner90}.


\subsection{Restaurantes chinos}
El proceso de los restaurantes chinos (\emph{Chinese restaurant process, CRP}) es un modelo originado en la rama de estad\'istica bayesiana no param'etrica.
Este modelo y otros similares, como el Buffet Indio (\emph{Indian Buffet}), han ganado mucha popularidad en aplicaci'ones como clustering donde no se quiere
pre-especificar el n'umero de clusters, y estimaci'on de distribuci'ones de probabilidades en espacios de muchas dimensiones.

Los restaurantes chinos son un caso particular de los Dirichlet Process en donde se tiene un proceso generativo sencillo de implementar.
Dado que el uso que se le dar'a a este modelo es puramente generativo, no se har'a incapi'e en los mecanimos necesarios para realizar inferencia
\footnote{El lector interesado en profundizar en este tema refierase a \cite{Teh2007} para un tutorial sobre Dirichlet Process y \cite{neal2000markov} sobre m'etodos Monte Carlo para realizar inferencia.}.
Metaf'oricamente, el modelo de los restaurantes chinos consiste en un restaurant con una cantidad infinita numerable de mesas\footnote{Parece ser que los restaurantes chinos de San Fansisco aparentan ser infinitos, y esto dio origen al nombre.}. 
En cada mesa, a su vez, pueden sentarse una cantidad no acotada de clientes. Inicialmente todas las mesas se encuentran vac'ias, 
y de a uno por vez empiezan a llegar los clientes. Cada cliente puede sentarse o bien en una mesa vac'ia o bien elegir una mesa de las ya ocupadas. 
Esto lo hace con la siguiente distribuci'on:
\begin{align}
\label{eq:crp_evolution}
P(\text{sentarse en mesa vacia}) =&\; \alpha/(N + \alpha)\\
P(\text{sentare en mesa } i) =&\; N(i)/(N + \alpha)
\end{align}

Siendo $N$ es la cantidad total de clientes en el restaurant, $N(i)$ es la cantidad de clientes en la mesa $i$, y $\alpha$ es un 
par'ametro que determina la \emph{concentraci'on} de clientes en cada mesa. Una propiedad que se utilizar'a m'as adelante es la llamada \emph{clustering property} de los Restaurantes Chinos.
Esta propiedad establece que si $m$ es la cantidad de mesas ocupadas, entonces

\begin{align}
\label{eq:crp_clustering}
E(m|N) \in O(\alpha\times log(N))
\end{align}

Este fen'omeno es conocido tambi'en como la propiedad de ``el rico se vuelve m'as rico''\footnote{\emph{The rich-gets-richer phenomenon} en ingl'es}. Este fen'omeno es el descripto por
las ecuaci'ones \ref{eq:crp_evolution}, puesto que la probabilidad de que alguien se siente en una mesa ocupada depende de la cantidad de gente ya sentada, entonces, el hecho
de que alguien se siente en una mesa aumenta la probabilidad de que en el futuro alguien elija esa mesa nuevamente.
