\section{Un modeo parcial para frases}
\label{sec:phrases}
Los modelos propuestos hasta el momento est'an focalizados en interacci'ones nota a nota. Sin embargo es bien sabido que la m'usica
tiene una estructura jer'arquica. En esta secci'on se trabajar'a un poco con un elemento de 'indole jer'arquico: la frase. 

Antes de intentar modelar una frase es importante tratar de entender de que se trata este objeto a modelar. El fraseo es una
noci'on complicada de definir, y es por esto que no existe una 'unica definici'on. William Rothstein en su libro Phrase Rhythm 
in Tonal Music, describe las dos mejores, seg'un su criterio, definiciones de frases. Comienza citando al compositor contemporaneo
Roger Sessions: 

\begin{quote} 
[\ldots] What, for instance, is a so-called `musical phrase` if not the portion of music that must be performed, so to speak, 
without letting go, or figuratively, in a single breath?. [\ldots] The phrase is a constant movement towards a goal - the cadence.
\end{quote}

Si bien esta definici'on lejos est'a de permitir construir un modelo generativo para frases, hay dos nociones que son interesantes. 
La primer noci'on es la del respiro: Una frase no puede ser arbitrariamente larga, tampoco puede ser arbitrariamente corta. La 
segunda, es que la frase tiene un \emph{goal}, y este \emph{goal} es la cadencia.%\alert{como defino cadencia?}. 

Luego Rothstein contin'ua citando la definici'on de Peter Westergaard quien distingue dos conjuntos de alturas, y define
a la frase como un movimiento entre estos dos conjuntos de forma tal que se cumplan las siguientes tres propiedades:
\begin{enumerate}
 \item Uno espera el segundo conjunto de alturas
 \item Uno tiene alguna noci'on de cuando este segundo conjunto ocurrir'a
 \item Una vez que el segundo conjunto de alturas ocurri'o, uno sabe que la frase lleg'o donde quer'ia ir
\end{enumerate}


Estas dos definiciones comparten la noci'on de meta; en la definici'on de Sessions, la meta es la cadencia y en la Westergaard 
por el segundo conjunto de notas.  En lo que sigue se propone un modelo que para tratar de capturar parcialmente esta nocion de frase.

\subsection{Las notas de apoyo}
Siguiendo las definiciones
de frase mel'odica vistas en la secci'on anterior, parece ser que la noci'on de meta es una noci'on importante, y que esta meta
est'a relacionada con la armon'ia de la pieza en cuesti'on. 

Tomando la definici'on de Westergaard, para poder hablar de frase, entonces es necesario primero saber cuales son los dos conjuntos de 
alturas entre los cuales la frase va a desplazarse. La forma m'as sencilla es pensar estos dos conjuntos como dos acordes sucesivos
y que la melod'ia que transcurre en un acorde en realidad est'a apuntanto hacia el acorde siguiente. Por supuesto
esta es una simplificaci'on, puesto que de la misma forma que existe una jerarqu'ia a nivel notas, existe tambi'en una jerarqu'ia
en la progresi'on arm'onica: Ciertos acordes cumplen un rol estructurante mientras que otros cumplen un rol decorativo. Tambi'en
existen acordes que si bien no son iguales, en ciertos contextos se los puede utilizar como \emph{substitutos}. 

Esta elecci'on de la frase como camino entre dos acordes sucesivos tampoco tiene en cuenta de forma directa la restricci'on 
que impone sobre la duraci'on de una frase la definici'on de Sessions, sin embargo es de esperarse que la duraci'on de los acordes de una pieza musical
no sea excesivamente larga ni corta. 

De esta forma, se propone como modelo, tomar, para cada acorde, una \emph{nota de apoyo}. Esta nota de apoyo ser'a la meta de 
la frase. Es importante que las notas de apoyo \emph{sean parte} de la frase que se est'a componiendo, es decir, las notas
de apoyo no pueden estar desconectadas del modelo probabilistico que vaya a elegir las notas anteriores y posteriores a la misma. 
Esto se puede expresar como propiedades en t'erminos del modelo que asigna probabilidades a las alturas. 
Estas propiedades descartar'an algunas frases y otras no, y se desea, dentro de las frases que restan, elegir una con probabilidad
proporcional a la que esta ten'ia en el conjunto original de frases. 

Esto en principio podr'ia ser exponencial, ya que la cantidad de posibles frases crece exponencialmente con la longitud de la frase.
Sin embargo, se puede aprovechar la localidad de los principios de Narmour para construir un algoritmo m'as eficiente.  

A continuaci'on se muestra c'omo construir este modelo. 


\subsection{Construcci\'on del submodelo}
\label{sec:phrase_model}
A continuaci'on se definir'a formalmente el problema, y luego se dar'a un algoritmo para resolverlo.

Se cuenta con un modelo que asigna probabilidades a notas seg'un la historia de las 'ultimas dos notas, $P(n_3 | n_1, n_2)$. Si bien se puede generalizar a $k$ notas,
la construcci'on quedar'ia menos clara, y el hecho es que se utilizar'a con solo 2 notas. Sup'ongase adem'as que se encuentra en un contexto formado por las notas 
$n_1, n_2$, y se desea generar una frase mel'odica de $d$ notas, de forma tal que se cumpla una cierta propiedad $M$ (middle) sobre la probabilidad de tocar las notas
del medio de la frase, y cierta propiedad $S$ (support) sobre la nota de apoyo de la siguiente frase.

Como no todas las melod'ias de $d$ notas van a garantizar esto, se desea descartar todas las melod'ias que no lo garantizan y construir un nuevo modelo, en donde
solo se puedan construir las melod'ias que cumplan con los predicados en cuesti'on. Por 'ultimo, se desea tambi'en que la probabilidad de estas l'ineas mel'odicas 
que satisfacen los predicados, sea proporcional a la asignada por el modelo original. 

La forma en la que se atacar'a este problema, es mediante una sucesi'on de conjuntos indexados por el contexto, la nota final y cuantas notas le queda
a la frase. Estos conjuntos tendr'an la propiedad de que cualquier nota elegida de ellos garantizar'a la existencia de una continuaci'on de la longitud correspondiente 
 y que \emph{lleve a buen puerto}. Utilizando esta propiedad, es posible implementar un algoritmo eficiente para elegir la frase dentro del submodelo. 

Para poder utilizarlo sin cuidado habr'a que demostrar la correctitud de este argumento, demostrando que cualquier frase mel'odica del submodelo se puede construir
utilizando esta serie de conjuntos. Por 'ultimo, la asignaci'on de probabilidades utilizar'a el modelo original, renormalizando en la sucesion de conjuntos. De esta 
forma la probabilidad ser'a proporcional al modelo original.

Tomando $M$ y $S$ como restricciones sobre las l'ineas mel'odicas, s'olo ser'an v'alidas las l'ineas $n_1, \cdots, n_k, n_f$ que cumplan con

$$  S(n_{k-1}, n_k, n_f) \land \forall i\leq k-2, M(n_i, n_{i+1}, n_{i+2})$$

Se puede dar una definici'on equivalente definiendo la funci'on $Poss$, que determina las notas suceptibles a ser notas de apoyo dado una cierta historia determinada por al menos dos notas.

\begin{definition}
\label{def:poss}
Sean $n_1, \cdots, n_k$ una sucesi'on de notas, $k\geq2$, se define
\begin{align*}
Poss(n_1, n_2, \cdots, n_k)= \left\{
 \begin{array}{rl}
  \phi & \text{si } \neg valid(n_1, \cdots, n_k) \\ %\exists i < k-1 \text{ tal que } \neg M(n_i, n_{i+1}, n_{i+2}) \\
   \{n_f / S(n_{k-1}, n_k, n_f)\} & \text{si no}
 \end{array} \right.
\end{align*}

Donde $valid(n_1, \cdots, n_k) = \forall i, i\leq k-2 \Rightarrow M(n_i, n_{i+1}, n_{i+2})$
\end{definition}

Se define inductivamente la funci'on $Must(n_1, n_2, n_f, d)$, que dado un contexto $n_1, n_2$ determina el conjunto de notas que habr'a que tocar, de forma tal
que $d$ notas despu'es, la probabilidad de la nota $n_f$ cumpla con $S$ de la siguiente forma:
\begin{definition}
\label{def:must}
\begin{align*}
Must(n_1, n_2, n_f, 1)=& \{n_3/ S(n_2, n_3, n_f) \land M(n_1, n_2, n_3)\}\\
Must(n_1, n_2, n_f, d)=& \{n_3/ Must(n_2, n_3, n_f, d) \neq \phi \land M(n_1,n_2, n_3)\}
\end{align*}
\end{definition}


\ \newline \textbf{Teorema.}
A continuaci'on se demuestra por inducci'on en $d$ que 
$$n \in Must(n_1, n_2, n_f, d) \Leftrightarrow \exists n'_1, \cdots, n'_{d-1} \text{ tales que } n_f \in Poss(n_1, n_2, n, n'_1, \cdots, n'_{d-1})$$

\ \newline \textbf{Demostraci'on.}

Cuando $d=1$
\begin{align*}
n \in Must(n_1, n_2, n_f, 1)   & \Leftrightarrow n \in \{n_3/ S(n_2, n_3, n_f) \land M(n_1, n_2, n_3)\} \\
                               & \Leftrightarrow S(n_2, n, n_f) \land M(n_1, n_2, n)   \\
                               & \Leftrightarrow n_f \in Poss(n_1, n_2, n)
\end{align*}

Suponiendo ahora que el predicado vale para $d$, 
\begin{align}
n \in Must(n_1, n_2, n_f, d+1)   & \Leftrightarrow n \in \{n_3/ Must(n_2, n_3, n_f, d) \neq \phi \land M(n_1,n_2, n_3)\} \nonumber \\
                                 & \Leftrightarrow Must(n_2, n, n_f, d) \neq \phi \land M(n_1,n_2, n) \nonumber \\
                                 & \Leftrightarrow \exists n'_1 \text{ tal que } n'_1 \in Must(n_2, n, n_f, d) \land M(n_1,n_2, n) \label{eq_must}
\end{align}

Utilizando la hip'otesis inductiva sabemos que 
$$  n'_1 \in Must(n_2, n, n_f, d) \Leftrightarrow \exists n'_2, \cdots, n'_{d} \text{ tales que } n_f \in Poss(n_2, n, n'_1, n'_2, \cdots, n'_{d})$$

Por lo tanto la equaci'on \ref{eq_must} es equivalente a
$$ \exists n'_1, n'_2, \cdots, n'_d \text{ tal que } n_f \in Poss(n_2, n, n'_1, \cdots, n'_d) \land M(n_1,n_2, n) $$
Lo 'unico que resta por demostrar es que 
$$ n_f \in Poss(n_2, n, n'_1, n'_2, \cdots, n'_d) \land M(n_1,n_2, n) \Leftrightarrow n_f \in Poss(n_1, n_2, n, n'_1, n'_2, \cdots, n'_d)$$
lo cual es v'alido por la definici'on de $Poss$, demostrando lo que se quer'ia demostrar$\qed$


Con esta definici'on, se define el proceso generativo de la siguiente forma:

\begin{algoritmo}
play_phrase(n1, n2, nf, d, prob_model)
    answer := []
    context := (n1, n2)
    para i desde d hasta 1 hacer
        n1, n2 := context
        candidates := Must(context, nf, i)
        n3 := pick(candidates, prob_model)
        answer.append(n3)
        context := (n2, n3) 
\end{algoritmo}





\subsection{Sobre los predicados $S$ y $M$}
\label{sec:must_predicates}
La definici'on de los predicados $S$ y $M$ son de crucial importancia, puesto que de definirlos de forma incorrecta resultar'a en un modelo vacio, 
es decir dados $n_1$ y $n_2$, ocurrir'a que no exista continuaci'on que permita tocar una nota de apoyo al final. 
Es por eso que se desean predicados que permitan definir restricciones, pero al mismo tiempo garantizen que siempre se puede tocar algo.

Una primera aproximaci'on que se tom'o fue definir 
$$S(n_1, n_2, n_3) = P(n_3 | n_1, n_2) \geq X\%$$

El problema ahora es determinar
el valor $X$. Como las probabilidades definidas por el modelo de Narmour estan formadas por un producto de cada uno de los principios, habria 
que considerar esto para la elecci'on de $X$. Adem'as, la elecci'on de un umbral no deja margen para la expermientaci'on con frases
mas o menos probables puesto que no es facil de controlar el hecho de que el modelo no se haga vacio. 
Por estas razones se descarto la idea de comparar la probabilidad dada por el contexto con una constante. 

Una propiedad deseable de un esquema para predicados $S$ y $M$ es que existan dos casos particulares, 
donde uno corresponda a la melod'ia m'as probable
y otro corresponda a eliminar la restricci'on de estos predicados, y adem'as garantize siempre la existencia de una frase. 

Un esquema que encaja dentro de este marco es un predicado compare la probabilidad $P(n_3 | n_1, n_2)$ con un 
$V_p$ percentil, es decir, el valor que deja s'olo al $p\%$ de las notas m'as probables.  De esta forma, si el contexto tiene muchos valores probables, 
el percentil se ajustar'a mas alto, y lo mismo para contextos menos probables.

Hay que tener en cuenta que dado que las observaciones son todas discretas, ser'a frecuente el caso donde 
se asigne exactamente la misma probabilidad a mas de un evento. En ese caso no se podr'a garantizar un $p\%$ puesto que ser'ia arbitrario
elegir un evento por sobre otro si tienen la misma probabilidad, sin embargo, no se considera que esto sea un mayor problema. Adem'as, este predicado nunca dejara un conjunto vacio, y si se lo define con cuidado, se puede obtener
el comportamiento de la melod'ia m'as probable, cambiando el predicado en el caso de $0\%$.


\section{Trabajo a futuro: silencios}
Los modelos propuestos hasta el momento no toman en cuenta al silencio. 
%\cite{PaieThesis} incorpora el silencio como un elemento m'as
%dentro de la generaci'on de alturas, sin embargo se considera que el silencio no es un elemento con el mismo status que las alturas. 
El silencio cambia su comportamiento seg'un el contexto donde este aparezca, y si bien esto tambi'en pasa con las notas, las reglas que se
aplican a este 'ultimo son otras. 

\cite{Margulis08} distingue dos roles del silencio dependiendo del contexto. Si la sonoridad gobernante est'a dada por un acorde de dominante
o de subdominante, un silenci'o aumenta la tensi'on que ya de por s'i generan dichos acordes, mientras que si la sonoridad gobernante
esta dada por un acorde de t'onica, el silencio disminuir'a m'as la tensi'on. Es por esto que se considera que los silencios no tienen 
un status igual que el resto de las notas, y su status es de tinte jer'arquico.

Se propone trabajar en el futuro incorporando los silencios como una componente de 'indole jerarquica conjuntamente con el fraseo.
